---
title: "The Titanic Kaggle Challenge"
author: "Chris Bemben"
date: "9/5/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

Details of this Kaggle challenge can be found [here](https://www.kaggle.com/c/titanic), the challenge is to accurately predict whether a passenger survived the shipwreck or not. The response variable is binary and since a passenger cannot partially survive the response variable will be either 1 or 0. This document will use the [Stan](https://mc-stan.org/) programming language and logistic regression to attack the challenge.

```{r, message=FALSE}
library(rstan)
library(rstanarm)
library(magrittr)
library(ggplot2)
library(titanic)

train <- titanic::titanic_train

train_idx <- sample(nrow(train), nrow(train)*0.8)
test_idx <- setdiff(seq_len(nrow(train)), train_idx)

str(train)
```

It's a common anecdote that women and children were the first passengers saved so the first model will only use age and gender as predictors. Since there is a substantial number of missing age values, nulls will be imputed, see the `Impute Passenger Age` function for the details of the imputation methodology or the `Exploratory Data Analysis` vignette to see the before after.

```{r}
train <- titanic::impute_passenger_age(train)
```


```{r, message=FALSE}
simple_model <- stanmodels$age_gender_model
print(simple_model)
```

```{r}
simple_fit <- sampling(
  simple_model,
  data = list(N=nrow(train[train_idx,]),
              age=train[train_idx,'Age'],
              sex=2,
              sex_idx=as.integer(train[train_idx,'Sex']),
              survived=train[train_idx,'Survived'],
              test_N=nrow(train[test_idx,]),
              test_age=train[test_idx,'Age'],
              test_sex_idx=as.integer(train[test_idx,'Sex'])
              ),
  seed = 1231
)
```

The model estimates an intercept for each `Sex` separately but shares the coefficient on age. The prior on `beta` is a standard normal distribution centered at 0 with a standard deviation of 1.

```{r}
print(simple_fit, pars=c('alpha','beta'))
```

Gender has a big impact on survival.

```{r, message=FALSE}
library(bayesplot)
samp <- rstan::extract(simple_fit)

mcmc_areas(
  simple_fit, 
  pars = c("alpha[1]","alpha[2]"),
  prob = 0.8, # 80% intervals
  prob_outer = 0.99, # 99%
  point_est = "mean"
)
```

## Fit Logistic Regression

Age is only explanatory variable at this time.

```{r, results="hide", message=FALSE}
age_logit_mod <- stanmodels$mod002_logit
```

```{r}
age_logit_fit <- sampling(
  age_logit_mod,
  data = list( N = nrow(train), 
               x = train$Age, 
               y = train$Survived, 
               N_new = nrow(test),
               cores = 4,
               x_new=test$Age),
  seed = 111
)
```

```{r}
age_logit_ext <- rstan::extract(age_logit_fit)

par(mfrow = c(3,1))
hist(age_logit_ext$alpha, main = 'alpha param')
hist(age_logit_ext$beta, main = 'beta param')
hist(age_logit_ext$y_rep, main = 'simulated survival')
```

```{r}
posterior <- as.array(age_logit_fit)
bayesplot::mcmc_scatter(posterior, pars=c("alpha","beta"))
```

```{r}
bayesplot::mcmc_intervals(posterior, pars=c("alpha","beta"))
```

```{r, message=FALSE}
#https://discourse.mc-stan.org/t/posterior-prediction-from-logit-regression/12217/2
postDF <- as.data.frame(age_logit_ext$y_new)
bayesplot::ppc_stat(y = as.integer(train$Survived[1:418]), yrep = as.matrix(postDF), stat = mean)
```

```{r, message=FALSE}
bayesplot::ppc_stat_grouped(y = as.integer(train$Survived[1:418]), yrep = as.matrix(postDF), stat = mean, group = train$Pclass[1:418])
```
The passenger class shows heterogeneitiy across passenger class. However, the model assumes the same survival rate across classes.

```{r, results="hide", message=FALSE}
age_logit_hier_mod <- stanmodels$mod002_logit_hier
```

```{r}
age_logit_hier_fit <- sampling(
              age_logit_hier_mod,
              data = list( N = nrow(train),
                           age = train$Age,
                           Pclass = 3,
                           pclass_idx = train$Pclass,
                           survival = train$Survived ),
              seed = 112,
              cores = 4)
```

The survival rate is similar to the actual data.

```{r}
print(age_logit_hier_fit, pars = c('alpha','beta'))
```

```{r}
age_logit_hier_ext <- rstan::extract(age_logit_hier_fit)
y_rep <- as.matrix(age_logit_hier_fit, pars = "y_rep")

ppc_stat_grouped(age_logit_hier_ext,
                 y = train$Survived,
                 yrep = y_rep[1:891,],
                 group = train$Pclass,
                 stat = "mean",
                 binwidth = 0.009)

```

Predict with new data
```{r}

beta_post <- age_logit_hier_ext$beta

# Function for simulating y based on new x
gen_quant_r <- function(age, Pclass) {
  alpha_post<- age_logit_hier_ext$alpha[,Pclass] #get intercept for class of passenger
  lin_comb <- sample(alpha_post, size = length(age)) + age*sample(beta_post, size = length(age))
  prob <- 1/(1 + exp(-lin_comb)) #inverse of logit link function
  out <- rbinom(length(age), 1, prob)
  return(out)
}

y_hat_tr <- gen_quant_r(train$Age, test$Pclass)
mean(y_hat_tr == train$Survived)
```

generate predictions on the test data
```{r}
#y_hat <- gen_quant_r(test$Age, test$Pclass)

# Accuracy
#pred_df <- data.frame(PassengerId = test$PassengerId, Survived=y_hat)
#write.csv(pred_df, file = "~/projectrepos/titanic/data/predict_20200918.csv", row.names = F)
```

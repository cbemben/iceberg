---
title: "The Titanic Kaggle Challenge"
author: "Chris Bemben"
date: "9/5/2020"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

Details of this Kaggle challenge can be found [here](https://www.kaggle.com/c/titanic), the challenge is to accurately predict whether a passenger survived the shipwreck or not. The response variable is binary and since a passenger cannot partially survive the response variable will be either 1 or 0. This document will use the [Stan](https://mc-stan.org/) programming language and logistic regression to attack the challenge.

```{r, message=FALSE}
library(rstan)
library(rstanarm)
library(magrittr)
library(ggplot2)
library(titanic)
library(bayesplot)

train <- titanic::titanic_train
test <- titanic::titanic_test

train_idx <- sample(nrow(train), nrow(train)*0.8)
test_idx <- setdiff(seq_len(nrow(train)), train_idx)

str(train)
```

It's a common anecdote that women and children were the first passengers saved so the first model will only use age and gender as predictors. Since there is a substantial number of missing age values, nulls will be imputed, see the `Impute Passenger Age` function for the details of the imputation methodology or the `Exploratory Data Analysis` vignette to see the before after.

```{r}
train <- titanic::impute_passenger_age(train)
test <- titanic:: impute_passenger_age(test)
```

The `Stan` program fits the model but also accepts a test dataset which will be used to make predictions. For more details on this approach see the `Stan` [manual](https://mc-stan.org/docs/2_24/stan-users-guide/prediction-forecasting-and-backcasting.html).
```{r, message=FALSE}
simple_model <- titanic::age_gender_stan(
                                          #N=nrow(train[train_idx,]),
                                          age=train[train_idx,'Age'],
                                          sex=2,
                                          sex_idx=as.integer(train[train_idx,'Sex']),
                                          survived=train[train_idx,'Survived'],
                                          #test_N=nrow(train[test_idx,]),
                                          test_age=train[test_idx,'Age'],
                                          test_sex_idx=as.integer(train[test_idx,'Sex']), seed=1234)
```

The model estimates an intercept for each `Sex` separately but shares the coefficient on age. The prior on `beta` is a standard normal distribution centered at 0 with a standard deviation of 1.

```{r}
print(simple_model, pars=c('alpha','beta'))
```

Gender has a big impact on survival.

```{r, message=FALSE}
samp <- rstan::extract(simple_model)

mcmc_areas(
  simple_model, 
  pars = c("alpha[1]","alpha[2]"),
  prob = 0.8, # 80% intervals
  prob_outer = 0.99, # 99%
  point_est = "mean"
)
```

```{r}
post_pred_df <- as.data.frame(samp$y_new)
bayesplot::ppc_stat(y = train[test_idx,"Survived"], yrep = as.matrix(post_pred_df), stat = mean, binwidth = .01)
bayesplot::ppc_stat_grouped(y = train[test_idx,"Survived"], yrep = as.matrix(post_pred_df), stat = mean, group = train[test_idx,"Sex"], binwidth = 0.03)
```

The plot above is comparing the predictions to the actual mean of the test dataset. The model is close but there's still a some variation the model is missing and individual predictions are still in need of review and for the Kaggle challenge we care about accuracy.

```{r}
mean(apply(samp$y_new, 2, median) %>% round(0) == train[test_idx,'Survived'])
```

Accuracy against a test set is about `r mean(apply(samp$y_new, 2, median) %>% round(0) == train[test_idx,'Survived'])` percent. There seems to be more to the story we need to consider to improve accuracy to a reasonable level.

Predict on the Kaggle challenge test set.

```{r}
predict_model <- titanic::age_gender_stan(age=train[train_idx,'Age'],
                                          sex=2,
                                          sex_idx=as.integer(train[train_idx,'Sex']),
                                          survived=train[train_idx,'Survived'],
                                          test_age=test$Age,
                                          test_sex_idx=as.integer(test$Sex)
                                         , seed=1234
                                         )
```

Export the predictions and push to Kaggle.

```{r}
pred_samp <- rstan::extract(predict_model)
test$Survived <- apply(pred_samp$y_new, 2, median)
#write.csv(test[,c("PassengerId","Survived")] ,file="inst/extdata/predict_20201002.csv", row.names = FALSE)
```

## Model Iteration

The anecdote we started with was that women and children were saved first and based on the initial model above this appears to be a true statement. To build on the anecdote, passengers with a higher societal standing also were given priority over lower-class passengers. To build on the model above, I'll add passenger class as an additional input into the model and see how much improvement is achieved.

```{r}
hier_mod <- titanic::age_gender_hier_stan(age=train[train_idx,'Age'],
                                    sex=2,
                                    sex_idx=as.integer(train[train_idx,'Sex']),
                                    survived=train[train_idx,'Survived'],
                                    test_age=train[test_idx,'Age'],
                                    test_sex_idx=as.integer(train[test_idx,'Sex'])
                                    , seed=124
                                    )
```

```{r}
hier_fit <- rstan::extract(hier_mod)
print(hier_mod, pars=c("alpha","beta"))
```

Checking the accuracy against my test partition.

```{r}
mean(apply(hier_fit$y_new, 2, median) %>% round(0) == train[test_idx,'Survived'])
```
The accuracy seems to have barely improved...

```{r}
hier_predict <- titanic::age_gender_hier_stan(age=train[train_idx,'Age'],
                                    sex=2,
                                    sex_idx=as.integer(train[train_idx,'Sex']),
                                    survived=train[train_idx,'Survived'],
                                    test_age=test$Age,
                                    test_sex_idx=as.integer(test$Sex)
                                    , seed=124
                                    )
```

Export the predictions and push to Kaggle.

```{r}
hier_pred <- rstan::extract(hier_predict)
test$Survived <- apply(hier_pred$y_new, 2, median)
#write.csv(test[,c("PassengerId","Survived")] ,file="inst/extdata/predict_20201005.csv", row.names = FALSE)
```
